import numpy as np
import matplotlib.pyplot as plt
import time

start=time.time()

img= plt.imread('Image which the code is to be applied on')
(h,w,d)= img.shape
X0= np.array(np.reshape(img, (h*w,d)))

# KMeans first
num_clust= 5

emeans= X0[np.random.choice(X0.shape[0], num_clust, replace=False ), :]

print("Initialised Centroids--", '\n', emeans)

print()


N= X0.shape[0]

labels= np.zeros(shape=(N,))

def  min_dist(arr, p_mat):
    return np.array([np.linalg.norm(arr- p_mat[i]) for i in range(p_mat.shape[0])])

def assignmt(X, centroids):
    n= centroids.shape[0]
    for j in range(N):
        labels[j]= np.argmin(min_dist(X[j], centroids))
        
    for i in range(n):
        if [labels==i]:
            centroids[i]= np.mean(X[labels==i], axis=0)
    return centroids

#Iterations 

num_iter= 50

for k in range(num_iter):
    emeans= assignmt(X0, emeans)

ecovs= np.array([np.cov((X0[labels==i]).T) for i in range(num_clust)])
ewts= np.array([(X0[labels==i]).shape[0] for i in range(num_clust)])/N


print('New centroids', '\n', emeans , '\n')
print()
print('Intra-cluster Covariance Matrices', '\n', ecovs, '\n')
print()
print('New weights', '\n', ewts)
print()

#Proceeding to use these results as initialisations for the GMM

likelihoods=[]

def pdf_norm(x, mean, cov):
    k = len(x)
    return ((2*np.pi)**(-k/2)) * ((np.linalg.det(cov))**(-0.5) ) * np.exp(-0.5*((x-mean).T@np.linalg.inv(cov)@(x-mean)))


def E_Step(X, means, covs, weights):
  
    N =X.shape[0] 
    def mix_pdf(x):
        M= means.shape[0]
        return np.array([pdf_norm(x, means[k], covs[k]) for k in range(M)])
    
    T = np.apply_along_axis(mix_pdf, 1, X) 
    
    wts_rep = np.tile(weights, (N, 1)) 

    U= T*wts_rep
    V= U/U.sum(axis=1)[:, None]
    
    l_hood= np.sum(np.log(np.sum(U, axis=1)))
    likelihoods.append(l_hood)
    
    return V

def M_Step(X, R, means, covs, weights):
    N, M= X.shape[0], means.shape[0]
    R_sum= np.sum(R, axis=0)
    
    new_wts= R_sum/N 
    
    #Updating the covariance matrices
    for n in range(M):
        new_mat= np.einsum('ij, j ->ij', (X-means[n]).T, (R.T)[n])
        covs[n]= new_mat@(X-means[n])
    
    new_covs= np.einsum('ijk,i->ijk', covs, 1/R_sum)
    
    #Updating the means
    
    new_means= ((X.T @R)/R_sum).T
    
    return new_means, new_covs, new_wts

#EM Iterations

num_iter2= 25

for i in range(num_iter2):
    T= E_Step(X0, emeans, ecovs, ewts)
    emeans, ecovs, ewts = M_Step(X0, T, emeans, ecovs, ewts)


resp_mat= E_Step(X0, emeans, ecovs, ewts)
Y= np.array([emeans[np.argmax(resp_mat[i])].astype(int) for i in range(N)])

new_img= Y.reshape(h,w,d)

plt.imshow(new_img)
plt.show()

for lhood in likelihoods:
    print(lhood)

end=time.time()

print('Final Means:', '\n', emeans, '\n')
print('Final Covariance Matrices:', '\n', ecovs, '\n')
print('Final Weights:', '\n', ewts, '\n')

print('Runtime(s)', '\n', end-start)






    

